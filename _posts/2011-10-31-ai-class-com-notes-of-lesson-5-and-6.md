---
layout: post
author: detro
published: true
title: "ai-class.com - Notes of Lesson 5 and 6"
tags: [classification, ai, prediction, course, lesson, linear regression, perceptron, maximum likelihood, six, laplacian smoothing, peter norvig, 5, online, 6, sebastian thrun, five, class, stanford, notes, smooth, machine learning, linear separator, occam's razor]
date: "2011-10-31 23:17:34"
updated: "2011-11-05 13:18:36"
permalink: /2011/11/01/ai-class-com---Notes-of-Lesson-5-and-6
---

If the "mood" of the [previous lessons](http://blog.ivandemarino.me/2011/10/23/ai-class-com---Notes-of-Lesson-3-and-4) was about Inference, I can only say that the current are about "[smooth](http://justinadayswork.files.wordpress.com/2009/10/swirl-stool.jpg?w=380)[ing](http://en.wikipedia.org/wiki/Smoothing)", "[occam's](http://crayfisher.files.wordpress.com/2011/10/occam.jpg) [razor](http://en.wikipedia.org/wiki/Occam's_razor)" and "[perce](http://www.autobots.tv/wp-content/uploads/2009/08/transformers-masterpiece.jpg)[ptron](http://en.wikipedia.org/wiki/Perceptron)". 3 concepts that will remain with you even after having forgotten about all this (check it out below :-P).

* [My notes of Lesson 5](http://www.evernote.com/shard/s1/sh/333fb301-8d12-4927-87ec-c81cdd42b7d2/240bbab26642f5d49d32c38053e905f6)
* [My notes of Lesson 6](http://www.evernote.com/shard/s1/sh/892ab4dc-c3a4-4089-b9de-8b3fdbe87d8e/82062527daaba376ac55a404199c2dc6)

Enjoy the notes and, again, do Lesson 5, than complete the Homework, than study Lesson 6.

**UPDATE Sat 05 Nov 2011:** I just finished putting down the notes of Lesson 6, and you can find the link above.

I must say that Lesson 6, if we exclude [Expectation Maximisation](http://en.wikipedia.org/wiki/Expectation%E2%80%93maximization_algorithm), is way less "mathematical" than the other lessons. Prof. Thrun, at a certain point, seems like givings us just an "overview" of some of the Unsupervised Learning concepts. It really makes you mouth-watering!
